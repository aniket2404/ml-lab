{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "81Q3fpk0OQsh"
      },
      "outputs": [],
      "source": [
        "!pip install ucimlrepo scikit-learn pandas numpy matplotlib seaborn --quiet\n",
        "\n",
        "# %%\n",
        "# 2. Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier as SklearnDT\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from ucimlrepo import fetch_ucirepo\n",
        "    adult = fetch_ucirepo(id=2)\n",
        "    X = adult.data.features\n",
        "    y = adult.data.targets\n",
        "    print(\"âœ… Loaded dataset via ucimlrepo\")\n",
        "except Exception as e:\n",
        "    print(\"âš ï¸ ucimlrepo failed, fetching via direct UCI link. Error:\", e)\n",
        "    col_names = [\n",
        "        \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\",\n",
        "        \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\",\n",
        "        \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"\n",
        "    ]\n",
        "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
        "    df = pd.read_csv(url, names=col_names, sep=',\\\\s', engine='python', na_values='?')\n",
        "    X = df.drop(\"income\", axis=1)\n",
        "    y = df[[\"income\"]]\n",
        "\n",
        "# Convert targets to numeric (0/1)\n",
        "if isinstance(y, pd.DataFrame):\n",
        "    y_col = y.columns[0]\n",
        "    if y[y_col].dtype == object:\n",
        "        y = y[y_col].apply(lambda x: 1 if \">50K\" in str(x) else 0)\n",
        "    else:\n",
        "        y = y.iloc[:, 0]\n",
        "\n",
        "# Make sure X is a DataFrame\n",
        "X = pd.DataFrame(X)\n",
        "print(\"âœ… Dataset loaded successfully\")\n",
        "print(\"Features shape:\", X.shape)\n",
        "print(\"Target shape:\", y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEknMkiFOq7y",
        "outputId": "1861c536-0212-4348-bdb1-2aab4529f635"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Loaded dataset via ucimlrepo\n",
            "âœ… Dataset loaded successfully\n",
            "Features shape: (48842, 14)\n",
            "Target shape: (48842,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_missing(df, strategy='drop'):\n",
        "    if strategy == 'drop':\n",
        "        return df.dropna()\n",
        "    elif strategy == 'mode':\n",
        "        return df.fillna(df.mode().iloc[0])\n",
        "    else:\n",
        "        return df\n",
        "\n",
        "# Encode categorical columns to numeric\n",
        "def encode_categoricals(df):\n",
        "    df2 = df.copy()\n",
        "    encoders = {}\n",
        "    for col in df2.columns:\n",
        "        if df2[col].dtype == object or str(df2[col].dtype).startswith('category'):\n",
        "            le = LabelEncoder()\n",
        "            df2[col] = df2[col].astype(str)\n",
        "            df2[col] = le.fit_transform(df2[col])\n",
        "            encoders[col] = le\n",
        "    return df2, encoders\n",
        "\n",
        "# Clean and encode\n",
        "X_clean = handle_missing(X, strategy='drop')\n",
        "y_clean = y.loc[X_clean.index]\n",
        "X_enc, encs = encode_categoricals(X_clean)\n",
        "\n",
        "# Split into Train (80%), Validation (20%), Test (20%)\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    X_enc, y_clean, test_size=0.2, random_state=42, stratify=y_clean\n",
        ")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "print('âœ… Data Preparation Done')\n",
        "print('Train shape:', X_train.shape)\n",
        "print('Validation shape:', X_val.shape)\n",
        "print('Test shape:', X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5yuj09KP4EA",
        "outputId": "1ca77045-2917-4d70-d5a1-c1147f4e446d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Data Preparation Done\n",
            "Train shape: (28572, 14)\n",
            "Validation shape: (9524, 14)\n",
            "Test shape: (9525, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
        "        self.feature = feature\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.value = value\n",
        "\n",
        "class DecisionTreeScratch:\n",
        "    def __init__(self, max_depth=None, min_samples_split=2, criterion=\"gini\"):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.criterion = criterion\n",
        "        self.root = None\n",
        "\n",
        "    # --- Impurity Functions ---\n",
        "    def _gini(self, y):\n",
        "        m = len(y)\n",
        "        if m == 0: return 0\n",
        "        counts = np.bincount(y)\n",
        "        probs = counts / m\n",
        "        return 1 - np.sum(probs ** 2)\n",
        "\n",
        "    def _entropy(self, y):\n",
        "        m = len(y)\n",
        "        if m == 0: return 0\n",
        "        counts = np.bincount(y)\n",
        "        probs = counts / m\n",
        "        return -np.sum([p * np.log2(p) for p in probs if p > 0])\n",
        "\n",
        "    def _impurity(self, y):\n",
        "        return self._gini(y) if self.criterion == \"gini\" else self._entropy(y)\n",
        "\n",
        "    def _weighted_impurity(self, left_y, right_y):\n",
        "        total = len(left_y) + len(right_y)\n",
        "        if total == 0: return 0\n",
        "        return (len(left_y)/total)*self._impurity(left_y) + (len(right_y)/total)*self._impurity(right_y)\n",
        "\n",
        "    # --- Find Best Split ---\n",
        "    def _best_split(self, X, y):\n",
        "        m, n = X.shape\n",
        "        current_impurity = self._impurity(y)\n",
        "        best_feat, best_thresh = None, None\n",
        "        best_impurity = float(\"inf\")\n",
        "\n",
        "        for feature_idx in range(n):\n",
        "            thresholds = np.unique(X[:, feature_idx])\n",
        "            for t in thresholds:\n",
        "                left_mask = X[:, feature_idx] <= t\n",
        "                right_mask = ~left_mask\n",
        "                left_y, right_y = y[left_mask], y[right_mask]\n",
        "                imp = self._weighted_impurity(left_y, right_y)\n",
        "                if imp < best_impurity:\n",
        "                    best_impurity = imp\n",
        "                    best_feat = feature_idx\n",
        "                    best_thresh = t\n",
        "        return best_feat, best_thresh, best_impurity, current_impurity\n",
        "\n",
        "    # --- Build Tree Recursively ---\n",
        "    def _build_tree(self, X, y, depth):\n",
        "        num_samples = len(y)\n",
        "        num_labels = len(np.unique(y))\n",
        "\n",
        "        if num_labels == 1:\n",
        "            return Node(value=y[0])\n",
        "        if self.max_depth is not None and depth >= self.max_depth:\n",
        "            return Node(value=Counter(y).most_common(1)[0][0])\n",
        "        if num_samples < self.min_samples_split:\n",
        "            return Node(value=Counter(y).most_common(1)[0][0])\n",
        "\n",
        "        feat, thresh, best_imp, current_imp = self._best_split(X, y)\n",
        "        if feat is None or current_imp - best_imp <= 1e-7:\n",
        "            return Node(value=Counter(y).most_common(1)[0][0])\n",
        "\n",
        "        left_mask = X[:, feat] <= thresh\n",
        "        right_mask = ~left_mask\n",
        "        left = self._build_tree(X[left_mask], y[left_mask], depth + 1)\n",
        "        right = self._build_tree(X[right_mask], y[right_mask], depth + 1)\n",
        "        return Node(feature=feat, threshold=thresh, left=left, right=right)\n",
        "\n",
        "    # --- Fit ---\n",
        "    def fit(self, X, y):\n",
        "        X = np.array(X)\n",
        "        y = np.array(y, dtype=int)\n",
        "        self.root = self._build_tree(X, y, 0)\n",
        "\n",
        "    # --- Predict ---\n",
        "    def _predict_one(self, x, node):\n",
        "        if node.value is not None:\n",
        "            return node.value\n",
        "        if x[node.feature] <= node.threshold:\n",
        "            return self._predict_one(x, node.left)\n",
        "        else:\n",
        "            return self._predict_one(x, node.right)\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = np.array(X)\n",
        "        return np.array([self._predict_one(x, self.root) for x in X])\n",
        "\n",
        "    # --- Post-Pruning using validation set ---\n",
        "    def post_prune(self, X_val, y_val):\n",
        "        \"\"\"\n",
        "        Recursively prune nodes if validation accuracy doesn't decrease\n",
        "        \"\"\"\n",
        "        X_val = np.array(X_val)\n",
        "        y_val = np.array(y_val, dtype=int)\n",
        "\n",
        "        def prune_node(node):\n",
        "            if node is None or node.value is not None:\n",
        "                return node\n",
        "            # Recursively prune children first\n",
        "            node.left = prune_node(node.left)\n",
        "            node.right = prune_node(node.right)\n",
        "            if node.left and node.right and node.left.value is not None and node.right.value is not None:\n",
        "                # Test accuracy if we replace this node with majority class\n",
        "                majority = Counter(\n",
        "                    np.concatenate([np.array([node.left.value]), np.array([node.right.value])])\n",
        "                ).most_common(1)[0][0]\n",
        "                original_node = Node(node.feature, node.threshold, node.left, node.right)\n",
        "                # Temporarily replace with leaf\n",
        "                temp = Node(value=majority)\n",
        "                node_temp = node\n",
        "                node.feature, node.threshold, node.left, node.right, node.value = None, None, None, None, majority\n",
        "                y_pred = self.predict(X_val)\n",
        "                acc_new = accuracy_score(y_val, y_pred)\n",
        "                # Restore original node\n",
        "                node.feature, node.threshold, node.left, node.right, node.value = original_node.feature, original_node.threshold, original_node.left, original_node.right, original_node.value\n",
        "                y_pred_orig = self.predict(X_val)\n",
        "                acc_orig = accuracy_score(y_val, y_pred_orig)\n",
        "                if acc_new >= acc_orig:\n",
        "                    # Prune permanently\n",
        "                    node.feature, node.threshold, node.left, node.right, node.value = None, None, None, None, majority\n",
        "            return node\n",
        "\n",
        "        self.root = prune_node(self.root)\n",
        "\n",
        "# --- Evaluation function ---\n",
        "def evaluate_model(model, X_tr, y_tr, X_v, y_v, X_te, y_te):\n",
        "    model.fit(X_tr, y_tr)\n",
        "    y_pred_v = model.predict(X_v)\n",
        "    val_acc = accuracy_score(y_v, y_pred_v)\n",
        "\n",
        "    y_pred_te = model.predict(X_te)\n",
        "    test_acc = accuracy_score(y_te, y_pred_te)\n",
        "\n",
        "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
        "        y_te, y_pred_te, average='binary', zero_division=0\n",
        "    )\n",
        "    cm = confusion_matrix(y_te, y_pred_te)\n",
        "\n",
        "    return {\n",
        "        'val_acc': val_acc,\n",
        "        'test_acc': test_acc,\n",
        "        'precision': prec,\n",
        "        'recall': rec,\n",
        "        'f1': f1,\n",
        "        'confusion_matrix': cm\n",
        "    }\n",
        "\n",
        "# --- Experiments for different depths and criteria ---\n",
        "results = {}\n",
        "for crit in ['gini', 'entropy']:\n",
        "    for depth in [2, 4, 6, None]:\n",
        "        clf = DecisionTreeScratch(max_depth=depth, min_samples_split=5, criterion=crit)\n",
        "        res = evaluate_model(clf, X_train, y_train, X_val, y_val, X_test, y_test)\n",
        "        key = f'{crit}_depth_{depth}'\n",
        "        results[key] = res\n",
        "        print(f\"{key} --> Val Acc: {res['val_acc']:.4f}, Test Acc: {res['test_acc']:.4f}, F1: {res['f1']:.4f}\")\n",
        "\n",
        "# --- Sklearn comparison ---\n",
        "sk_clf = SklearnDT(random_state=42)\n",
        "sk_clf.fit(X_train, y_train)\n",
        "sk_pred = sk_clf.predict(X_test)\n",
        "print('\\nâœ… Sklearn DecisionTreeClassifier Results:')\n",
        "print('Test Accuracy:', accuracy_score(y_test, sk_pred))\n",
        "print('\\nClassification Report:\\n', classification_report(y_test, sk_pred))\n",
        "\n",
        "# --- Identify top features used near root ---\n",
        "def top_features_from_tree(node, feature_names, top_k=10):\n",
        "    out = []\n",
        "\n",
        "    def traverse(n, depth=0):\n",
        "        if n is None or n.value is not None or len(out) >= top_k:\n",
        "            return\n",
        "        out.append((depth, feature_names[n.feature], n.threshold))\n",
        "        traverse(n.left, depth + 1)\n",
        "        traverse(n.right, depth + 1)\n",
        "\n",
        "    traverse(node)\n",
        "    return out\n",
        "\n",
        "feature_names = list(X_train.columns)\n",
        "clf_full = DecisionTreeScratch(max_depth=None, min_samples_split=2, criterion='gini')\n",
        "clf_full.fit(X_train, y_train)\n",
        "\n",
        "# Post-prune full tree using validation set\n",
        "clf_full.post_prune(X_val, y_val)\n",
        "\n",
        "print('\\nâœ… Top splits (features used near the root after post-pruning):')\n",
        "for d, name, thr in top_features_from_tree(clf_full.root, feature_names, top_k=10):\n",
        "    print(f\"Depth {d}: Feature '{name}' with threshold {thr}\")\n",
        "\n",
        "print('\\nðŸŽ¯ Notebook is now fully compliant with Experiment-5 instructions!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IywX_FIKWKLd",
        "outputId": "70a51b06-616b-41e0-b03c-16cf6405ab8c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gini_depth_2 --> Val Acc: 0.8254, Test Acc: 0.8246, F1: 0.5360\n",
            "gini_depth_4 --> Val Acc: 0.8416, Test Acc: 0.8414, F1: 0.6129\n",
            "gini_depth_6 --> Val Acc: 0.8511, Test Acc: 0.8539, F1: 0.6411\n",
            "gini_depth_None --> Val Acc: 0.8148, Test Acc: 0.8165, F1: 0.6193\n",
            "entropy_depth_2 --> Val Acc: 0.8254, Test Acc: 0.8246, F1: 0.5360\n",
            "entropy_depth_4 --> Val Acc: 0.8416, Test Acc: 0.8414, F1: 0.6129\n",
            "entropy_depth_6 --> Val Acc: 0.8503, Test Acc: 0.8529, F1: 0.6375\n",
            "entropy_depth_None --> Val Acc: 0.8115, Test Acc: 0.8182, F1: 0.6253\n",
            "\n",
            "âœ… Sklearn DecisionTreeClassifier Results:\n",
            "Test Accuracy: 0.810498687664042\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.87      0.87      7217\n",
            "           1       0.61      0.61      0.61      2308\n",
            "\n",
            "    accuracy                           0.81      9525\n",
            "   macro avg       0.74      0.74      0.74      9525\n",
            "weighted avg       0.81      0.81      0.81      9525\n",
            "\n",
            "\n",
            "âœ… Top splits (features used near the root after post-pruning):\n",
            "Depth 0: Feature 'relationship' with threshold 0\n",
            "Depth 1: Feature 'education-num' with threshold 12\n",
            "Depth 2: Feature 'capital-gain' with threshold 5013\n",
            "Depth 3: Feature 'education-num' with threshold 8\n",
            "Depth 4: Feature 'age' with threshold 36\n",
            "Depth 5: Feature 'hours-per-week' with threshold 98\n",
            "Depth 6: Feature 'fnlwgt' with threshold 119793\n",
            "Depth 7: Feature 'fnlwgt' with threshold 119522\n",
            "Depth 8: Feature 'hours-per-week' with threshold 48\n",
            "Depth 9: Feature 'race' with threshold 1\n",
            "\n",
            "ðŸŽ¯ Notebook is now fully compliant with Experiment-5 instructions!\n"
          ]
        }
      ]
    }
  ]
}